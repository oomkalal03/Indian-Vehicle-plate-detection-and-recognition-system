{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "#     load the data\n",
    "#     x has array of images and y has its value \n",
    "#     y -> 0 for not plate    y -> 1 for plate\n",
    "    X, y = load_data()\n",
    "    \n",
    "#     split the data into train and test using train_test_split\n",
    "    \n",
    "#     train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: \n",
    "#     for training data and for testing data\n",
    "\n",
    "#     The dataset will be split with 30% as the test dataset.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#     define sequential layers in the neural network\n",
    "    model = Sequential()\n",
    "\n",
    "#     adding 6 convolutional layers \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(rate=0.35))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test= np.array(y_test)\n",
    "\n",
    "#     train the neural network for 12 epochs\n",
    "    model.fit(X_train, y_train, epochs=12, validation_data=(X_test, y_test))\n",
    "\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('Loss score:', score[0])\n",
    "    print('Test accuracy:', score[1] * 100, '%')\n",
    "    \n",
    "    model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n",
      "Epoch 1/12\n",
      "114/114 [==============================] - 173s 2s/step - loss: 0.6958 - accuracy: 0.7802 - val_loss: 0.4622 - val_accuracy: 0.7042\n",
      "Epoch 2/12\n",
      "114/114 [==============================] - 152s 1s/step - loss: 0.2408 - accuracy: 0.9199 - val_loss: 0.1798 - val_accuracy: 0.9411\n",
      "Epoch 3/12\n",
      "114/114 [==============================] - 152s 1s/step - loss: 0.1583 - accuracy: 0.9506 - val_loss: 0.1167 - val_accuracy: 0.9731\n",
      "Epoch 4/12\n",
      "114/114 [==============================] - 154s 1s/step - loss: 0.1395 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9398\n",
      "Epoch 5/12\n",
      "114/114 [==============================] - 153s 1s/step - loss: 0.1673 - accuracy: 0.9459 - val_loss: 0.1261 - val_accuracy: 0.9661\n",
      "Epoch 6/12\n",
      "114/114 [==============================] - 154s 1s/step - loss: 0.1048 - accuracy: 0.9679 - val_loss: 0.1332 - val_accuracy: 0.9635\n",
      "Epoch 7/12\n",
      "114/114 [==============================] - 154s 1s/step - loss: 0.1118 - accuracy: 0.9619 - val_loss: 0.0830 - val_accuracy: 0.9718\n",
      "Epoch 8/12\n",
      "114/114 [==============================] - 155s 1s/step - loss: 0.0931 - accuracy: 0.9693 - val_loss: 0.0899 - val_accuracy: 0.9712\n",
      "Epoch 9/12\n",
      "114/114 [==============================] - 156s 1s/step - loss: 0.0912 - accuracy: 0.9712 - val_loss: 0.0975 - val_accuracy: 0.9763\n",
      "Epoch 10/12\n",
      "114/114 [==============================] - 151s 1s/step - loss: 0.0857 - accuracy: 0.9734 - val_loss: 0.1019 - val_accuracy: 0.9738\n",
      "Epoch 11/12\n",
      "114/114 [==============================] - 152s 1s/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 0.0712 - val_accuracy: 0.9782\n",
      "Epoch 12/12\n",
      "114/114 [==============================] - 154s 1s/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "49/49 [==============================] - 16s 334ms/step - loss: 0.0682 - accuracy: 0.9846\n",
      "Loss score: 0.06818394362926483\n",
      "Test accuracy: 98.4635055065155 %\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "print('Saving the model')\n",
    "load_model()\n",
    "print('Model saved successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
